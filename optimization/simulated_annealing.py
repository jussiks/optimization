#!/usr/bin/env python

"""Simulated annealing algorithm for function optimization.

@author: jussiks
"""

import math
import numpy
import random
import itertools
import copy
from optimization import Problem, Solution, generate_variables
from genetic_methods import gaussian_mutation


def simulated_annealing(problem, iterations=100, T=100, 
                        temp_func=0.95, print_iterations=False):
    """Optimizes a function using simulated annealing.

    Annealing process is stopped after maximum number of iterations is reached.
    
    TODO: add a stopping criterion after reaching certain temperature.
    
    Arguments:
    problem         Problem to be optimized.
    iterations      Maximum number of iterations. Default 100.
    T               Initial temperature. Default 100.
    temp_func       Coefficient applied to temperature after each iteration. 
                    Default 0.95    
    print_iterations
                    Boolean. Determines whether the best value is printed after
                    each iteration.
    """

    # Create a random initial solution within domain and set it as
    # all time best.
    sol = Solution(problem, generate_variables(problem))
    best = copy.deepcopy(sol)

    for i in range(iterations):
        # Generate a new solution in the neighbourhood of x. Neighbour is
        # generated by adding a normally distributed random number (mean = 0,
        # sd = 0.5) to each value in x.
        # TODO improve neighbour selection, maybe scale it with domain range
        # and number of iterations to make sure all values are reachable.

        sol_new = copy.deepcopy(sol)
        gaussian_mutation(
            sol_new, 1, [(high - low) * 0.25
                         for low, high in problem.variable_bounds]
            )

        sol_new.evaluate()

        if sol_new.value < sol.value:
            # New solution was better, accept it unconditionally
            sol = copy.deepcopy(sol_new)

            if sol.value < best.value:
                # Set the solution as all time best
                best = copy.deepcopy(sol)
        elif random.random() < math.exp((sol.value - sol_new.value) / T):
            # New solution was worse, but we still accept it
            sol = copy.deepcopy(sol_new)

        if print_iterations:
            print(">>", i, best)

        # Adjust the temperature
        T *= temp_func
    return best


if __name__ == "__main__":
    # Testing the algorithm with various settings.
    T               = [20, 50, 150]
    temp_func       = [0.5, 0.7, 0.95]
    iterations      = [200, 500, 1000]

    func = lambda x: math.cos(x[0]) * math.sin(x[1]) - float(x[0]) / (x[1]**2 + 1)
    bounds = [(-1, 2), (-1, 1)]

    # Eamon function for testing. Should produce x = [pi, pi]   
    #func = lambda x: - math.cos(x[0]) * math.cos(x[1]) * math.exp(-(x[0] - math.pi)**2 - (x[1] - math.pi)**2)
    #bounds = [(-10, 10), (-10, 10)]

    problem = Problem(func, variable_bounds=bounds)

    # Creates a list of all possible combinations (3*3*3 = 27) of T, temp_func
    # and iterations and runs the algorithm for each.
    combinations = list(itertools.product(T, temp_func, iterations))

    print("Minimize {0}".format(problem))
    for c in combinations:
        t, tf, i = c
        x = simulated_annealing(
            problem,
            iterations=i, T=t, temp_func=tf,
            print_iterations=False)
        print("T: {0}, temp_func: {1}, iterations: {2}".format(t, tf, i))
        print("Best value: x = {0}, f(x) = {1}\n".format(x.variables, x.value))
